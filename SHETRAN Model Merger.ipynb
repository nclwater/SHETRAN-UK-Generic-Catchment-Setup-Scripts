{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a91aad",
   "metadata": {},
   "source": [
    "# SHETRAN Model Merger\n",
    "\n",
    "*October 2025*\n",
    "\n",
    "This code will take existing SHETRAN setups and merge them. This is designed to work with nested catchments with a single outflow. Models should all work individually and must each have the following files:\n",
    "- Library xml\n",
    "- Subsurface map\n",
    "- Land cover map\n",
    "- Lake map\n",
    "\n",
    "The model library paths should be given in the order that they are to be merged, starting with the largest and working towards the smallest. Map files should be finable using the paths in the library file (normally in the same folder as the library file).\n",
    "\n",
    "The script works by loading the largest catchment, making this the base for additional catchments. A nested catchment is then loaded, the soil and vegetation detail numbers are increased so that they do not overlap with the existing values. They are then added to the library file and the base soil, landcover, and lake maps overwrite the existing ones. This is then repeated for each additional catchment. Onve complete, the library file and soil and land cover maps are simplified so that there is no duplication.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "- All maps are aligned to the same grid.\n",
    "- All maps have the same *nodata* values.\n",
    "- Maps within the same simulation share the same extent (masks from subsurface are used for land cover and lakes). If this is not the case then you can make multiple masks.\n",
    "\n",
    "**Troubleshooting**\n",
    "\n",
    "You could get the error *IndexError: boolean index did not match indexed array along dimension 0; dimension is 1 but corresponding boolean dimension is 29* if the files are not the same shape. This is possible if they have been built differently or have a column/row of NA around the edges. Check this manually (or improve the code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6502a2e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:34:45.920317200Z",
     "start_time": "2025-10-09T16:34:45.880715600Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Preamble ---\n",
    "import SHETRAN_GB_Master_Setup_Functions as smf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- Paths to Library Files ---\n",
    "root = 'C:/Users/nbs65/Newcastle University/Anna Murgatroyd - Shetran-Anglian/05 - SHETRAN Modelling/'\n",
    "\n",
    "# List these in order of decreasing size.\n",
    "model_paths = [\n",
    "    os.path.join(root, '03 Uncalibrated APM Models with Superficials', 'Heigham', f'Heigham_LibraryFile.xml'),\n",
    "    os.path.join(root, '04 Optimised Models with Superficials', '34004', f'34004_LibraryFile.xml'),\n",
    "    os.path.join(root, '04 Optimised Models with Superficials', '34005', f'34005_LibraryFile.xml')\n",
    "]\n",
    "# Write the output path of the library file:\n",
    "output_Library_path = os.path.join(root, '05 Heigham/Heigham - PycalSF 34004 34005/Heigham_LibraryFile.xml')\n",
    "\n",
    "\n",
    "# --- Functions ---\n",
    "def extract_xml_parameter(xml_line):\n",
    "    \"\"\"\n",
    "    This will take a full line from the library file and return the parameter value.\n",
    "     '<PrecipitationTimeSeriesData>43018_Precip.csv</PrecipitationTimeSeriesData>\\n' --> '43018_Precip.csv'\n",
    "    \"\"\"\n",
    "    return xml_line.split('>')[1].split('<')[0]\n",
    "\n",
    "\n",
    "def remove_library_lines(library_lines, line_name):\n",
    "    \"\"\"\n",
    "    This function will remove lines from a library file relating to a block of XLM parameters, such as \n",
    "    VegetationDetail, SoilProperty, SoilDetail. It will return the cleaned list of lines.\n",
    "    :param: library_lines: list of strings. The lines of the library file to clean \n",
    "    :param: line_name: string. The name of the XML block to remove, e.g. 'VegetationDetail'\n",
    "    \"\"\"\n",
    "\n",
    "    # Clean the existing lines_master of the lines that we want to replace:\n",
    "    lines_cleaned = []\n",
    "    for line in library_lines:\n",
    "        if line.startswith(f'<{line_name}>'):\n",
    "            continue\n",
    "        else:\n",
    "            lines_cleaned.append(line)\n",
    "    return lines_cleaned\n",
    "\n",
    "\n",
    "def add_library_lines(lines_to_recieve, lines_to_add, block_name, header=None):\n",
    "    \"\"\"\n",
    "    This function will add lines to a library file relating to a block of XLM parameters, such as \n",
    "    VegetationDetail, SoilProperty, SoilDetail. It will return the updated list of lines.\n",
    "    :param: lines_to_recieve: list of strings. The lines of the library file to add to\n",
    "    :param: lines_to_add: list of strings. The lines to add to the library file. End lines with '\\n'.\n",
    "    :param: block_name: string. The name of the XML block to add, e.g. 'VegetationDetails'\n",
    "    :param: header: string. An optional header line to add before the lines_to_add. End header with '\\n'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add the updated lines in lines_updated:\n",
    "    lines_updated = []\n",
    "    for line in lines_to_recieve:\n",
    "\n",
    "        if line.startswith(f'<{block_name}>'):\n",
    "            lines_updated.append(line)\n",
    "            if header!=None:\n",
    "                lines_updated.append(header)\n",
    "            for l in lines_to_add:\n",
    "                lines_updated.append(l)\n",
    "\n",
    "        else:\n",
    "            lines_updated.append(line)\n",
    "    \n",
    "    return lines_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "126d6c39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:34:50.666052500Z",
     "start_time": "2025-10-09T16:34:50.341262100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C:/Users/nbs65/Newcastle University/Anna Murgatroyd - Shetran-Anglian/05 - SHETRAN Modelling/03 Uncalibrated APM Models with Superficials\\Heigham\\Heigham_LibraryFile.xml\n",
      "1 C:/Users/nbs65/Newcastle University/Anna Murgatroyd - Shetran-Anglian/05 - SHETRAN Modelling/04 Optimised Models with Superficials\\34004\\34004_LibraryFile.xml\n",
      "2 C:/Users/nbs65/Newcastle University/Anna Murgatroyd - Shetran-Anglian/05 - SHETRAN Modelling/04 Optimised Models with Superficials\\34005\\34005_LibraryFile.xml\n"
     ]
    }
   ],
   "source": [
    "# 1. Iterate through each model path:\n",
    "for i, library_path in enumerate(model_paths):\n",
    "    print(i, library_path)\n",
    "\n",
    "    # Load the model files:\n",
    "    with open(library_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Get file paths from the library file:\n",
    "    subsurface_path = [extract_xml_parameter(l) for l in lines if l.startswith('<SoilMap>')][0]\n",
    "    landcover_path = [extract_xml_parameter(l) for l in lines if l.startswith('<VegMap>')][0]\n",
    "    lake_path = [extract_xml_parameter(l) for l in lines if l.startswith('<LakeMap>')][0]\n",
    "\n",
    "    # Add in the library folder path:\n",
    "    base_path = os.path.dirname(library_path)\n",
    "    subsurface_path = os.path.join(base_path, subsurface_path)\n",
    "    landcover_path = os.path.join(base_path, landcover_path)\n",
    "    lake_path = os.path.join(base_path, lake_path)\n",
    "\n",
    "    # Load in the subsurface raster files so that they can be merged with another on the next loop:\n",
    "    if i == 0:\n",
    "        subsurface_master, ncols_l, nrows_l, xll_l, yll_l, cellsize_l, nodata_l, _, _ = smf.read_ascii_raster(subsurface_path)\n",
    "        landcover_master = smf.read_ascii_raster(landcover_path, return_metadata=False)\n",
    "        lake_master = smf.read_ascii_raster(lake_path, return_metadata=False)\n",
    "\n",
    "        # Make the first library file the master Library File:\n",
    "        lines_master = lines\n",
    "\n",
    "        # Collate the master details:\n",
    "        cover_lines, soilprop_lines, soildetail_lines = [], [], []\n",
    "        for line in lines:\n",
    "            if line.startswith('<VegetationDetail>'):\n",
    "                cover_lines.append(line)\n",
    "            elif line.startswith('<SoilProperty>'):\n",
    "                soilprop_lines.append(line)\n",
    "            elif line.startswith('<SoilDetail>'):\n",
    "                soildetail_lines.append(line)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Remove the header from the master lines:\n",
    "        cover_lines = cover_lines[1:]\n",
    "        soilprop_lines = soilprop_lines[1:]\n",
    "        soildetail_lines = soildetail_lines[1:]\n",
    "\n",
    "    else:\n",
    "        subsurface_new, ncols_s, nrows_s, xll_s, yll_s, cellsize_s, nodata, _, _ = smf.read_ascii_raster(subsurface_path)\n",
    "        landcover_new = smf.read_ascii_raster(landcover_path, return_metadata=False)\n",
    "        lake_new = smf.read_ascii_raster(lake_path, return_metadata=False)\n",
    "\n",
    "        # 2. Calculate the starting row/col in the large raster where the small raster should be placed\n",
    "        row_start = int((yll_s - yll_l) / cellsize_l)\n",
    "        col_start = int((xll_s - xll_l) / cellsize_l)\n",
    "\n",
    "        # Calculate the starting row from the top (NumPy row 0 is the top)\n",
    "        row_start = int((yll_l + nrows_l * cellsize_l - yll_s - nrows_s * cellsize_s) / cellsize_l)\n",
    "        col_start = int((xll_s - xll_l) / cellsize_l)\n",
    "\n",
    "        # 3. Add the new raster to the master raster, ensuring that the values do not overlap by adding the highest existing map value.\n",
    "        mask = (subsurface_new != nodata)\n",
    "\n",
    "        subsurface_master[row_start:row_start+nrows_s, col_start:col_start+ncols_s][mask] = subsurface_new[mask]+subsurface_master.max()\n",
    "        landcover_master[row_start:row_start+nrows_s, col_start:col_start+ncols_s][mask] = landcover_new[mask]+landcover_master.max()\n",
    "        lake_master[row_start:row_start+nrows_s, col_start:col_start+ncols_s][mask] = lake_new[mask]  # Don't add, this is binary.\n",
    "\n",
    "        # Add the new library file detials to the main library file:\n",
    "        # Collate the soil detials:\n",
    "        temp_cover_lines, temp_soilprop_lines, temp_soildetail_lines = [], [], []\n",
    "        for line in lines:\n",
    "            if line.startswith('<VegetationDetail>'):\n",
    "                temp_cover_lines.append(line)\n",
    "            elif line.startswith('<SoilProperty>'):\n",
    "                temp_soilprop_lines.append(line)\n",
    "            elif line.startswith('<SoilDetail>'):\n",
    "                temp_soildetail_lines.append(line)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Remove the header from the temp lines:\n",
    "        temp_cover_lines = temp_cover_lines[1:]\n",
    "        temp_soilprop_lines = temp_soilprop_lines[1:]\n",
    "        temp_soildetail_lines = temp_soildetail_lines[1:]\n",
    "\n",
    "        # Change the Veg Type in the temp_cover_lines so that they don't overlap with the master cover_lines:\n",
    "        cover_max = max([int(extract_xml_parameter(x).split(',')[0]) for x in cover_lines])\n",
    "        for line in temp_cover_lines:\n",
    "            line_split = extract_xml_parameter(line).split(',')\n",
    "            line_split[0] = str(int(line_split[0]) + cover_max)\n",
    "            new_line = '<VegetationDetail>' + ','.join(line_split) + '</VegetationDetail>\\n'\n",
    "            cover_lines.append(new_line)\n",
    "\n",
    "        # Change the Soil Number in the temp_soilprop_lines so that they don't overlap with the master soilprop_lines:\n",
    "        soilprop_max = max([int(extract_xml_parameter(x).split(',')[0]) for x in soilprop_lines])\n",
    "        for line in temp_soilprop_lines:\n",
    "            line_split = extract_xml_parameter(line).split(',')\n",
    "            line_split[0] = str(int(line_split[0]) + soilprop_max)\n",
    "            new_line = '<SoilProperty>' + ','.join(line_split) + '</SoilProperty>\\n'\n",
    "            soilprop_lines.append(new_line)\n",
    "        \n",
    "\n",
    "        # Change the Soil Catagory and the Soil Type in the SoilDetail lines to match the Soil Properties:\n",
    "        soildetail_max = max([float(extract_xml_parameter(x).split(',')[0]) for x in soildetail_lines])\n",
    "        for line in temp_soildetail_lines:\n",
    "            line_split = extract_xml_parameter(line).split(',')\n",
    "            line_split[0] = str(float(line_split[0]) + soildetail_max)\n",
    "            line_split[2] = str(float(line_split[2]) + soilprop_max)\n",
    "            new_line = '<SoilDetail>' + ','.join(line_split) + '</SoilDetail>\\n'\n",
    "            soildetail_lines.append(new_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11cd977",
   "metadata": {},
   "source": [
    "## Rewrite the new Library File and model files:\n",
    "\n",
    "Slip the combined vegetations and soils into the original library file.\n",
    "\n",
    "Then save them to a new folder.\n",
    "\n",
    "Then go back through and remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92914610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:34:56.798357300Z",
     "start_time": "2025-10-09T16:34:56.764062400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the existing lines_master of the lines that we want to replace:\n",
    "lines_cleaned = remove_library_lines(lines_master, 'VegetationDetail')\n",
    "lines_cleaned = remove_library_lines(lines_cleaned, 'SoilProperty')\n",
    "lines_cleaned = remove_library_lines(lines_cleaned, 'SoilDetail')\n",
    "\n",
    "# Add the updated lines in lines_updated:\n",
    "lines_updated = add_library_lines(\n",
    "    lines_cleaned, cover_lines, 'VegetationDetails', \n",
    "    header='<VegetationDetail>Veg Type #, Vegetation Type, Canopy storage capacity (mm), Leaf area index, Maximum rooting depth(m), AE/PE at field capacity,Strickler overland flow coefficient</VegetationDetail>\\n')\n",
    "\n",
    "lines_updated = add_library_lines(\n",
    "    lines_updated, soilprop_lines, 'SoilProperties',\n",
    "    header='<SoilProperty>Soil Number,Soil Type, Saturated Water Content, Residual Water Content, Saturated Conductivity (m/day), vanGenuchten- alpha (cm-1), vanGenuchten-n</SoilProperty> Avoid spaces in the Soil type names\\n')\n",
    "\n",
    "lines_updated = add_library_lines(\n",
    "    lines_updated, soildetail_lines, 'SoilDetails',\n",
    "    header='<SoilDetail>Soil Category, Soil Layer, Soil Type, Depth at base of layer (m)</SoilDetail>\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034e0d3",
   "metadata": {},
   "source": [
    "## Write the files to a new folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c40592b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:35:05.963976600Z",
     "start_time": "2025-10-09T16:35:05.700505Z"
    }
   },
   "outputs": [],
   "source": [
    "output_folder = os.path.dirname(output_Library_path)\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Write the updated library file:\n",
    "with open(os.path.join(output_Library_path), 'w') as file:\n",
    "    file.writelines(lines_updated)\n",
    "\n",
    "# Get file paths from the library file:\n",
    "subsurface_path = [extract_xml_parameter(l) for l in lines_updated if l.startswith('<SoilMap>')][0]\n",
    "landcover_path = [extract_xml_parameter(l) for l in lines_updated if l.startswith('<VegMap>')][0]\n",
    "lake_path = [extract_xml_parameter(l) for l in lines_updated if l.startswith('<LakeMap>')][0]\n",
    "\n",
    "# Write the updated raster files:\n",
    "smf.write_ascii(subsurface_master, os.path.join(output_folder, subsurface_path),\n",
    "                xllcorner=xll_l, yllcorner=yll_l, cellsize=cellsize_l, \n",
    "                ncols=ncols_l, nrows=nrows_l)\n",
    "\n",
    "smf.write_ascii(landcover_master, os.path.join(output_folder, landcover_path),\n",
    "                xllcorner=xll_l, yllcorner=yll_l, cellsize=cellsize_l, \n",
    "                ncols=ncols_l, nrows=nrows_l)\n",
    "\n",
    "smf.write_ascii(lake_master, os.path.join(output_folder, lake_path),\n",
    "                xllcorner=xll_l, yllcorner=yll_l, cellsize=cellsize_l, \n",
    "                ncols=ncols_l, nrows=nrows_l)\n",
    "\n",
    "# Copy the remaining files to the new folder:\n",
    "smf.copy_library_inputs(\n",
    "        library_filepath=model_paths[0], \n",
    "        new_folder=output_folder,\n",
    "        required_files=[\"<DEMMeanFileName>\", \"<DEMminFileName>\", \"<MaskFileName>\", \n",
    "                        \"<PrecipMap>\", \"<PeMap>\", \n",
    "                        \"<PrecipitationTimeSeriesData>\", \n",
    "                        \"<EvaporationTimeSeriesData>\", \n",
    "                        \"<MaxTempTimeSeriesData>\"\n",
    "                        ],\n",
    "                        copy_library=False)  # copy_library must be False, else you'll get the original library file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ba673",
   "metadata": {},
   "source": [
    "## Simplify the Files\n",
    "\n",
    "The library files and rasters are now probably very full of duplicated values. You may want to leave these so that you can distinguish between the soils in the different catchments (i.e. if you want to calibrate them individually).\n",
    "\n",
    "If you want to simplify the catchment however, then the code below will remove duplicates from the soil and vegetation rasters and library tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_path_to_simplify = \"S:/11 - Anglian Water Catchments (HEIF Grant 2025)/New setup with superficials/34004 Merged/34004_LibraryFile.xml\"\n",
    "\n",
    "# Load the model files:\n",
    "with open(library_path_to_simplify, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Get file paths from the library file:\n",
    "subsurface_path = [extract_xml_parameter(l) for l in lines if l.startswith('<SoilMap>')][0]\n",
    "landcover_path = [extract_xml_parameter(l) for l in lines if l.startswith('<VegMap>')][0]\n",
    "lake_path = [extract_xml_parameter(l) for l in lines if l.startswith('<LakeMap>')][0]\n",
    "\n",
    "# Add in the library folder path:\n",
    "base_path = os.path.dirname(library_path_to_simplify)\n",
    "subsurface_path = os.path.join(base_path, subsurface_path)\n",
    "landcover_path = os.path.join(base_path, landcover_path)\n",
    "lake_path = os.path.join(base_path, lake_path)\n",
    "\n",
    "# Load in the subsurface raster files so that they can be merged with another on the next loop:\n",
    "subsurface_master, ncols_l, nrows_l, xll_l, yll_l, cellsize_l, nodata_l, _, _ = smf.read_ascii_raster(subsurface_path).astype(int)\n",
    "landcover_master = smf.read_ascii_raster(landcover_path, return_metadata=False).astype(int)\n",
    "lake_master = smf.read_ascii_raster(lake_path, return_metadata=False).astype(int)\n",
    "\n",
    "# Collate the master details:\n",
    "cover_lines, soilprop_lines, soildetail_lines = [], [], []\n",
    "for line in lines:\n",
    "    if line.startswith('<VegetationDetail>'):\n",
    "        cover_lines.append(line)\n",
    "    elif line.startswith('<SoilProperty>'):\n",
    "        soilprop_lines.append(line)\n",
    "    elif line.startswith('<SoilDetail>'):\n",
    "        soildetail_lines.append(line)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# map, mc, mr, mx, my, mcs, mnd, _, _ = read_ascii_raster(map_path, data_type=int, replace_NA=False)\n",
    "veg_cols = ['Veg Type', 'Vegetation Type', 'Canopy storage capacity (mm)', 'Leaf area index', 'Maximum rooting depth(m)', 'AE/PE at field capacity', 'Strickler overland flow coefficient']\n",
    "soil_prop_cols = ['Soil Number', 'Soil Type', 'Saturated Water Content', 'Residual Water Content', 'Saturated Conductivity (m/day)', 'vanGenuchten- alpha (cm-1)', 'vanGenuchten-n']\n",
    "soil_detail_cols = ['Soil Category', 'Soil Layer', 'Soil Type', 'Depth at base of layer (m)']\n",
    "\n",
    "# --- Remove duplicates from the Land Cover table:\n",
    "group_cols = [v for v in veg_cols if v != 'Veg Type']\n",
    "\n",
    "# Convert to a dataframe:\n",
    "table = [extract_xml_parameter(line).split(',') for line in cover_lines[1:]]\n",
    "table = pd.DataFrame(table, columns=veg_cols)\n",
    "\n",
    "# Group the rows in table using all columns except 'Veg Type':\n",
    "groups = table.groupby(group_cols)['Veg Type'].apply(list).reset_index()['Veg Type']\n",
    "\n",
    "# Run throug the groups:\n",
    "for group in groups:\n",
    "    # Find minimum ID: \n",
    "    new_ID = min([float(x) for x in group])\n",
    "    \n",
    "    # Change the duplicated IDs to the new ID in the map:\n",
    "    for old_ID in group:\n",
    "        landcover_master[landcover_master == float(old_ID)] = new_ID\n",
    "\n",
    "table.drop_duplicates(subset=group_cols, keep='first', inplace=True)\n",
    "\n",
    "# Reset the indexes so that they run consecutively:\n",
    "counter = 1\n",
    "for old_ID in sorted(table['Veg Type']):\n",
    "    print(old_ID, counter)\n",
    "    # Table:\n",
    "    table.loc[table['Veg Type'] == old_ID, 'Veg Type'] = counter\n",
    "    # Map\n",
    "    landcover_master[landcover_master == int(old_ID)] = counter\n",
    "    counter+=1\n",
    "\n",
    "# Convert the table back to lines:\n",
    "cover_lines_updated = ['<VegetationDetail>' + ','.join([str(v) for v in row]) + '</VegetationDetail>\\n' for i, row in table.iterrows()]\n",
    "\n",
    "# Write out the simplified land cover map:\n",
    "smf.write_ascii(array=landcover_master, ascii_ouput_path=landcover_path.replace('.asc', f'_simple.asc'),\n",
    "                xllcorner=xll_l, yllcorner=yll_l, cellsize=cellsize_l, ncols=ncols_l, nrows=nrows_l, \n",
    "                NODATA_value=nodata_l, data_format= '%1.0f')\n",
    "\n",
    "# --- Remove duplicates from the Soil Number table:\n",
    "\n",
    "# --- Now change edit the soil details to match the de-duplicated Soil numbers produced above.\n",
    "\n",
    "# --- Now remove duplicates in the Soil Details Table and the Subsurface Map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93459acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS SECTION FOR MERGING THE LIENS BACK INTO THE LIBRARY FILE:\n",
    "lines_cleaned = remove_library_lines(lines, 'VegetationDetail')\n",
    "lines_updated = add_library_lines(\n",
    "    lines_cleaned, table_lines, 'VegetationDetails', \n",
    "    '<VegetationDetail>Veg Type #, Vegetation Type, Canopy storage capacity (mm), Leaf area index, Maximum rooting depth(m), AE/PE at field capacity,Strickler overland flow coefficient</VegetationDetail>\\n')\n",
    "lines_updated\n",
    "\n",
    "# # Remove the duplicated rows from the table and write it to csv:\n",
    "# table.to_csv(table_path.replace('.csv', f'{output_suffix}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767499b8",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e98e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_master[landcover_master == -9999] = 0\n",
    "plt.imshow(landcover_master, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "30054c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1, -9999,     2,     4,     5,     3])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(landcover_master.flatten()).unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
